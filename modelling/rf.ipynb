{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring RandomForest Models for Crop Classification - DLBS \n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook investigates the performance of RandomForest models in crop classification using the Zueri Crop dataset. Various configurations of the RandomForest model, including different numbers of estimators and class weight settings, will be explored. The goal is to analyze how these hyperparameters impact the model's accuracy and generalization on crop classification tasks. The notebook utilizes the `DeepModel_Trainer` class for data loading and model training, and evaluation metrics are logged using WandB for comprehensive analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "if os.getcwd().endswith(\"modelling\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import future\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.modelling import DeepModel_Trainer\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import wandb\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set numpy random state\n",
    "random_state = 123\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# silence wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "# HDF5 file path\n",
    "file_name_zueri = r'D:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Random Forest Fitting\n",
    "\n",
    "The provided Python functions are essential components of a RandomForest-based model training and evaluation pipeline. The `prepare_data_fold` function reshapes input and target tensors, while `fit_rf` trains a RandomForest model using specified training data. The `predict_rf` function utilizes the trained model for making predictions on new data. The `evaluate_log` function assesses model performance, logs various metrics with WandB, and generates a confusion matrix visualization. Additionally, the `load_data_train` and `load_data_test` functions load and concatenate training and testing data batches, respectively. This collective set of functions constitutes a comprehensive workflow for training, predicting, and evaluating RandomForest models in a machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_wandb_run(\n",
    "    project_name: str,\n",
    "    run_group: str,\n",
    "    fold: int,\n",
    "    model_architecture: str,\n",
    "    batchsize: int,\n",
    "    seed: int,\n",
    "    entity: str = \"dlbs_crop\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Sets a new run up (used for k-fold)\n",
    "    :param str project_name: Name of the project in wandb.\n",
    "    :param str run_group: Name of the project in wandb.\n",
    "    :param str fold: number of the executing fold\n",
    "    :param str model_architecture: Modeltype (architectur) of the model\n",
    "    :param int batchsize\n",
    "    :param int seed\n",
    "    \"\"\"\n",
    "    # init wandb\n",
    "    run = wandb.init(\n",
    "        settings=wandb.Settings(start_method=\"thread\"),\n",
    "        project=project_name,\n",
    "        entity=entity,\n",
    "        name=f\"{fold}-Fold\",\n",
    "        group=run_group,\n",
    "        config={\n",
    "            \"model architecture\": model_architecture,\n",
    "            \"batchsize\": batchsize,\n",
    "            \"seed\": seed\n",
    "        },\n",
    "    )\n",
    "    return run\n",
    "\n",
    "\n",
    "def load_data_train(model_trainer: DeepModel_Trainer):\n",
    "    \"\"\"\n",
    "    Load and concatenate training data batches.\n",
    "\n",
    "    Args:\n",
    "        model_trainer (DeepModel_Trainer): Trainer object containing the training data loader.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Loaded and concatenated input and target tensors for training.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store batches\n",
    "    all_data_input = []\n",
    "    all_data_target = []\n",
    "\n",
    "    # Iterate through the DataLoader\n",
    "    for batch in model_trainer.train_loader:\n",
    "        input, _, target_2, _ = batch\n",
    "        all_data_input.append(input)\n",
    "        all_data_target.append(target_2)\n",
    "\n",
    "    # Concatenate all batches into a single tensor along the batch dimension (dim=0)\n",
    "    input_train = torch.cat(all_data_input, dim=0)\n",
    "    target_train = torch.cat(all_data_target, dim=0)\n",
    "    return input_train, target_train\n",
    "\n",
    "\n",
    "def load_data_test(model_trainer: DeepModel_Trainer):\n",
    "    \"\"\"\n",
    "    Load and concatenate testing data batches.\n",
    "\n",
    "    Args:\n",
    "        model_trainer (DeepModel_Trainer): Trainer object containing the testing data loader.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Loaded and concatenated input and target tensors for testing.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store batches\n",
    "    all_data_input = []\n",
    "    all_data_target = []\n",
    "\n",
    "    # Iterate through the DataLoader\n",
    "    for batch in model_trainer.test_loader:\n",
    "        input, _, target_2, _ = batch\n",
    "        all_data_input.append(input)\n",
    "        all_data_target.append(target_2)\n",
    "\n",
    "    # Concatenate all batches into a single tensor along the batch dimension (dim=0)\n",
    "    input_test = torch.cat(all_data_input, dim=0)\n",
    "    target_test = torch.cat(all_data_target, dim=0)\n",
    "    return input_test, target_test\n",
    "\n",
    "\n",
    "def prepare_data_fold(input: torch.Tensor, target: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Prepare the input and target data for training or testing.\n",
    "\n",
    "    Args:\n",
    "        input (torch.Tensor): Input data tensor.\n",
    "        target (torch.Tensor): Target data tensor.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Reshaped input and target tensors.\n",
    "    \"\"\"\n",
    "    reshape_factor = len(input) // 10\n",
    "    input = input[0:reshape_factor * 10]\n",
    "    target = target[0:reshape_factor * 10]\n",
    "    reshaped_tensor = input.reshape(24 * reshape_factor, 24 * 10, 4)\n",
    "    reshaped_target = target.reshape(24 * reshape_factor, 24 * 10)\n",
    "\n",
    "    return reshaped_tensor, reshaped_target\n",
    "\n",
    "\n",
    "def fit_rf(clf: RandomForestClassifier, reshaped_tensor_train: torch.Tensor, reshaped_target_train: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Fit a RandomForest model on the training data.\n",
    "\n",
    "    Args:\n",
    "        clf (RandomForestClassifier): RandomForest model.\n",
    "        reshaped_tensor_train (torch.Tensor): Reshaped input tensor for training.\n",
    "        reshaped_target_train (torch.Tensor): Reshaped target tensor for training.\n",
    "\n",
    "    Returns:\n",
    "        RandomForestClassifier: Trained RandomForest model.\n",
    "    \"\"\"\n",
    "    clf = future.fit_segmenter(\n",
    "        reshaped_target_train, reshaped_tensor_train, clf)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def predict_rf(model: RandomForestClassifier, reshaped_tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Make predictions using a trained RandomForest model.\n",
    "\n",
    "    Args:\n",
    "        model (RandomForestClassifier): Trained RandomForest model.\n",
    "        reshaped_tensor (torch.Tensor): Reshaped input tensor for prediction.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predicted labels.\n",
    "    \"\"\"\n",
    "    y_pred = future.predict_segmenter(reshaped_tensor, model)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate_log(reshaped_target_train, y_pred, wandbrun, verbose: bool = False,\n",
    "                 class_names_cm=[\"0_unknown\", \"Field crops\", \"Forest\",\n",
    "                                 \"Grassland\", \"Orchards\", \"Special crops\"],\n",
    "                 is_test: bool = False):\n",
    "    \"\"\"\n",
    "    Evaluate and log performance metrics using WandB.\n",
    "\n",
    "    Args:\n",
    "        reshaped_target_train (torch.Tensor): Reshaped target tensor for training.\n",
    "        y_pred (np.ndarray): Predicted labels.\n",
    "        wandbrun (wandb.Run): WandB run object.\n",
    "        verbose (bool, optional): Whether to print verbose information. Defaults to False.\n",
    "        class_names_cm (List[str], optional): List of class names for confusion matrix. Defaults to [\"0_unknown\", \"Field crops\", \"Forest\", \"Grassland\", \"Orchards\", \"Special crops\"].\n",
    "        is_test (bool, optional): Whether the evaluation is on the test set. Defaults to False.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(\n",
    "        reshaped_target_train.numpy().ravel(), y_pred.ravel())\n",
    "    conf_matrix = confusion_matrix(\n",
    "        reshaped_target_train.numpy().ravel(), y_pred.ravel())\n",
    "    f1score = f1_score(reshaped_target_train.numpy().ravel(),\n",
    "                       y_pred.ravel(), average=None)\n",
    "    # Log the F1 scores for each class\n",
    "    if is_test:\n",
    "        f1_scores_dict = {\n",
    "            \"F1-Score_test_\" + class_names_cm[i]: f1score[i] for i in range(len(f1score))}\n",
    "    else:\n",
    "        f1_scores_dict = {\n",
    "            \"F1-Score_train_\" + class_names_cm[i]: f1score[i] for i in range(len(f1score))}\n",
    "    wandbrun.log(f1_scores_dict)\n",
    "    if verbose:\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"f1scores:\", f1_scores_dict)\n",
    "    if is_test:\n",
    "        wandbrun.log({'accuracy_test': accuracy})\n",
    "        wandbrun.log(f1_scores_dict)\n",
    "    else:\n",
    "        wandbrun.log({'accuracy_train': accuracy})\n",
    "        wandbrun.log(f1_scores_dict)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                cbar=False, xticklabels=class_names_cm,\n",
    "                yticklabels=class_names_cm)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    if is_test:\n",
    "        wandbrun.log({\"confusion_matrix_test\": wandb.Image(plt)})\n",
    "    else:\n",
    "        wandbrun.log({\"confusion_matrix_train\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def train_evaluate_rf(clf: RandomForestClassifier, trainer: DeepModel_Trainer, run_group=\"RandomForest-Baseline\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a RandomForest model using WandB for logging.\n",
    "\n",
    "    Args:\n",
    "        clf (RandomForestClassifier): RandomForest model to be trained.\n",
    "        trainer (DeepModel_Trainer): Trainer object containing training and testing data loaders.\n",
    "        run_group (str, optional): Name of the run group in WandB. Defaults to \"RandomForest-Baseline\".\n",
    "    \"\"\"\n",
    "    # Initialize the WandB run\n",
    "    run = setup_wandb_run(project_name=\"dlbs_crop-rf\",\n",
    "                          run_group=run_group,\n",
    "                          fold='all', model_architecture=\"RandomForest\",\n",
    "                          batchsize='Full', seed=random_state)\n",
    "\n",
    "    # Create data loaders\n",
    "    trainer.create_loader()\n",
    "\n",
    "    # Load and prepare training data\n",
    "    input_train, target_train = load_data_train(trainer)\n",
    "    reshaped_tensor_train, reshaped_target_train = prepare_data_fold(\n",
    "        input_train, target_train)\n",
    "\n",
    "    # Fit RandomForest model on training data\n",
    "    rfmodel = fit_rf(clf, reshaped_tensor_train, reshaped_target_train)\n",
    "\n",
    "    # Predict on the training set\n",
    "    y_pred_train = predict_rf(rfmodel, reshaped_tensor_train)\n",
    "\n",
    "    # Evaluate and log training performance\n",
    "    evaluate_log(reshaped_target_train, y_pred_train, run, verbose=True)\n",
    "\n",
    "    # Load and prepare testing data\n",
    "    input_test, target_test = load_data_test(trainer)\n",
    "    reshaped_tensor_test, reshaped_target_test = prepare_data_fold(\n",
    "        input_test, target_test)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_test = predict_rf(rfmodel, reshaped_tensor_test)\n",
    "\n",
    "    # Evaluate and log testing performance\n",
    "    evaluate_log(reshaped_target_test, y_pred_test,\n",
    "                 run, verbose=True, is_test=True)\n",
    "\n",
    "    # Finish WandB run\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate Random Forests\n",
    "\n",
    "The code iterates over different numbers of estimators in a RandomForest model, using a `DeepModel_Trainer` to load data and labels from an HDF5 file. For each iteration, a RandomForest model is trained and evaluated with specific parameters, and the results are logged using WandB. Additionally, a separate evaluation is conducted with 150 estimators without class weights. This iterative process systematically explores RandomForest configurations, providing insights into model performance variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over different numbers of estimators\n",
    "for estimators in [300, 200, 150, 100, 50, 20, 10]:\n",
    "    # Initialize DeepModel_Trainer with data and labels\n",
    "    trainer = DeepModel_Trainer(file_name_zueri, 'labels.csv', None, 'cpu')\n",
    "\n",
    "    # Create RandomForestClassifier with specified parameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=estimators, n_jobs=-1, class_weight={0: 1e-10, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1})\n",
    "\n",
    "    # Train and evaluate RandomForest model\n",
    "    train_evaluate_rf(clf, trainer, f\"RandomForest-Baseline-{estimators}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate RandomForest model with 150 estimators and no class weights\n",
    "trainer = DeepModel_Trainer(file_name_zueri, 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=150, n_jobs=-1)\n",
    "\n",
    "# Train and evaluate RandomForest model without class weights\n",
    "train_evaluate_rf(clf, trainer, \"RandomForest-Baseline-150-No-Weight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgroLuege--zjmSdF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
