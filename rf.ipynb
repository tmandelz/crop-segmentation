{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import segmentation, future\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.dataset import Dataset\n",
    "from src.modelling import DeepModel_Trainer\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import wandb\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_zueri = r'D:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5'\n",
    "# file_name_zueri = r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5'\n",
    "random_state = 123\n",
    "np.random.seed(random_state)\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "def setup_wandb_run(\n",
    "    project_name: str,\n",
    "    run_group: str,\n",
    "    fold: int,\n",
    "    model_architecture: str,\n",
    "    batchsize: int,\n",
    "    seed:int,\n",
    "    entity:str=\"dlbs_crop\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Sets a new run up (used for k-fold)\n",
    "    :param str project_name: Name of the project in wandb.\n",
    "    :param str run_group: Name of the project in wandb.\n",
    "    :param str fold: number of the executing fold\n",
    "    :param str model_architecture: Modeltype (architectur) of the model\n",
    "    :param int batchsize\n",
    "    :param int seed\n",
    "    \"\"\"\n",
    "    # init wandb\n",
    "    run = wandb.init(\n",
    "        settings=wandb.Settings(start_method=\"thread\"),\n",
    "        project=project_name,\n",
    "        entity=entity,\n",
    "        name=f\"{fold}-Fold\",\n",
    "        group=run_group,\n",
    "        config={\n",
    "            \"model architecture\": model_architecture,\n",
    "            \"batchsize\": batchsize,\n",
    "            \"seed\":seed\n",
    "        },\n",
    "    )\n",
    "    return run\n",
    "\n",
    "def load_data_train(model_trainer):\n",
    "    #     # Initialize an empty list to store batches\n",
    "    all_data_input = []\n",
    "    all_data_target = []\n",
    "    # Iterate through the DataLoader\n",
    "    for batch in model_trainer.train_loader:\n",
    "        input, _, target_2, _ = batch\n",
    "\n",
    "        all_data_input.append(input)\n",
    "        all_data_target.append(target_2)\n",
    "\n",
    "    # Concatenate all batches into a single tensor along the batch dimension (dim=0)\n",
    "    input_train = torch.cat(all_data_input, dim=0)\n",
    "    target_train = torch.cat(all_data_target, dim=0)\n",
    "    return input_train,target_train\n",
    "\n",
    "def load_data_test(model_trainer):\n",
    "    #     # Initialize an empty list to store batches\n",
    "    all_data_input = []\n",
    "    all_data_target = []\n",
    "    # Iterate through the DataLoader\n",
    "    for batch in model_trainer.test_loader:\n",
    "        input, _, target_2, _ = batch\n",
    "\n",
    "        all_data_input.append(input)\n",
    "        all_data_target.append(target_2)\n",
    "\n",
    "    # Concatenate all batches into a single tensor along the batch dimension (dim=0)\n",
    "    input_test = torch.cat(all_data_input, dim=0)\n",
    "    target_test= torch.cat(all_data_target, dim=0)\n",
    "    return input_test,target_test\n",
    "\n",
    "def prepare_data_fold(input,target):\n",
    "    reshape_factor = len(input) // 10 \n",
    "    input= input[0:reshape_factor*10]\n",
    "    target = target[0:reshape_factor*10]\n",
    "    reshaped_tensor = input.reshape(24*reshape_factor, 24*10, 4)\n",
    "    reshaped_target = target.reshape(24*reshape_factor, 24*10)\n",
    "\n",
    "    return reshaped_tensor,reshaped_target\n",
    "\n",
    "def fit_rf(clf:RandomForestClassifier,reshaped_tensor_train,reshaped_target_train):\n",
    "    clf = future.fit_segmenter(reshaped_target_train, reshaped_tensor_train, clf)\n",
    "    return clf\n",
    "\n",
    "def predict_rf(model:RandomForestClassifier,reshaped_tensor):\n",
    "    y_pred = future.predict_segmenter(reshaped_tensor, model)\n",
    "    return y_pred\n",
    "\n",
    "def evaluate_log(reshaped_target_train,y_pred,wandbrun,verbose:bool=False,\n",
    "                 class_names_cm =[\"0_unknown\",\"Field crops\",\"Forest\",\"Grassland\",\"Orchards\",\"Special crops\"],is_test:bool=False):\n",
    "    \n",
    "    accuracy = accuracy_score(reshaped_target_train.numpy().ravel(), y_pred.ravel())\n",
    "    conf_matrix = confusion_matrix(reshaped_target_train.numpy().ravel(), y_pred.ravel())\n",
    "    f1score = f1_score(reshaped_target_train.numpy().ravel(), y_pred.ravel(), average=None)\n",
    "    # Log the F1 scores for each class\n",
    "    if is_test:\n",
    "        f1_scores_dict = {\"F1-Score_test_\"+class_names_cm[i]: f1score[i] for i in range(len(f1score))}\n",
    "    else:\n",
    "        f1_scores_dict = {\"F1-Score_train_\"+class_names_cm[i]: f1score[i] for i in range(len(f1score))}\n",
    "    wandbrun.log(f1_scores_dict)\n",
    "    if verbose:\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"f1scores:\", f1_scores_dict)\n",
    "    if is_test:\n",
    "        wandbrun.log({'accuracy_test': accuracy})\n",
    "        wandbrun.log(f1_scores_dict)\n",
    "    else:\n",
    "        wandbrun.log({'accuracy_train': accuracy})\n",
    "        wandbrun.log(f1_scores_dict)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                cbar=False, xticklabels=class_names_cm,\n",
    "                yticklabels=class_names_cm)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    if is_test:\n",
    "        wandbrun.log({\"confusion_matrix_test\": wandb.Image(plt)})\n",
    "    else:\n",
    "        wandbrun.log({\"confusion_matrix_train\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "\n",
    "def train_evaluate_rf(clf,trainer:DeepModel_Trainer, run_group=\"RandomForest-Baseline\"):\n",
    "    # init the wandb run\n",
    "    run = setup_wandb_run(project_name=\"dlbs_crop-rf\",\n",
    "                            run_group=run_group,\n",
    "                            fold='all', model_architecture=\"RandomForest\",\n",
    "                            batchsize='Full',seed=random_state)\n",
    "    trainer.create_loader()\n",
    "    input_train,target_train = load_data_train(trainer)\n",
    "    reshaped_tensor_train,reshaped_target_train = prepare_data_fold(input_train,target_train)\n",
    "    rfmodel = fit_rf(clf,reshaped_tensor_train,reshaped_target_train)\n",
    "    y_pred_train = predict_rf(rfmodel,reshaped_tensor_train)\n",
    "\n",
    "    evaluate_log(reshaped_target_train,y_pred_train,run,verbose=True)\n",
    "\n",
    "    input_test,target_test= load_data_test(trainer)\n",
    "    reshaped_tensor_test,reshaped_target_test = prepare_data_fold(input_test,target_test)\n",
    "    y_pred_test = predict_rf(rfmodel,reshaped_tensor_test)\n",
    "\n",
    "    evaluate_log(reshaped_target_test,y_pred_test,run,verbose=True,is_test=True)\n",
    "    wandb.finish()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=300,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=200,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=150,n_jobs=-1)\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-150-No-Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=150,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=100,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=50,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=20,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepModel_Trainer(r'C:\\Temp\\AgroLuege\\raw_data\\ZueriCrop\\ZueriCrop.hdf5', 'labels.csv', None, 'cpu')\n",
    "clf = RandomForestClassifier(n_estimators=10,n_jobs=-1,class_weight={0: 1e-10, 1: 1, 2:1 ,3:1 ,4:1 ,5:1})\n",
    "train_evaluate_rf(clf,trainer,\"RandomForest-Baseline-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgroLuege--zjmSdF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
